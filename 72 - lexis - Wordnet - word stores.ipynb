{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#A-little-peek-at-Lemmas\" data-toc-modified-id=\"A-little-peek-at-Lemmas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>A little peek at Lemmas</a></span><ul class=\"toc-item\"><li><span><a href=\"#You-can-get-meaning-information-directly\" data-toc-modified-id=\"You-can-get-meaning-information-directly-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>You can get meaning information directly</a></span></li><li><span><a href=\"#Multiple-lemma-names\" data-toc-modified-id=\"Multiple-lemma-names-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Multiple lemma names</a></span></li><li><span><a href=\"#Grammatical-roles\" data-toc-modified-id=\"Grammatical-roles-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Grammatical roles</a></span></li></ul></li><li><span><a href=\"#Use-cases\" data-toc-modified-id=\"Use-cases-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Use cases</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-words-containing...\" data-toc-modified-id=\"Find-words-containing...-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Find words containing...</a></span></li><li><span><a href=\"#Substring\" data-toc-modified-id=\"Substring-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Substring</a></span></li><li><span><a href=\"#Pattern-(regular-expression)\" data-toc-modified-id=\"Pattern-(regular-expression)-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Pattern (regular expression)</a></span></li><li><span><a href=\"#palindromes\" data-toc-modified-id=\"palindromes-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>palindromes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Which-of-these-are-(or-rather-&quot;can-be&quot;)-a-verb?\" data-toc-modified-id=\"Which-of-these-are-(or-rather-&quot;can-be&quot;)-a-verb?-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Which of these are (or rather \"can be\") a verb?</a></span></li><li><span><a href=\"#Making-functions-operable\" data-toc-modified-id=\"Making-functions-operable-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Making functions operable</a></span></li></ul></li><li><span><a href=\"#Only-p,-q,-b,-d,-and-vowels\" data-toc-modified-id=\"Only-p,-q,-b,-d,-and-vowels-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Only p, q, b, d, and vowels</a></span><ul class=\"toc-item\"><li><span><a href=\"#Containing-i,-e,-p-in-that-order,-with-other-letters-in-between\" data-toc-modified-id=\"Containing-i,-e,-p-in-that-order,-with-other-letters-in-between-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Containing i, e, p in that order, with other letters in between</a></span></li></ul></li><li><span><a href=\"#S-words\" data-toc-modified-id=\"S-words-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>S-words</a></span></li></ul></li><li><span><a href=\"#Search-expansion\" data-toc-modified-id=\"Search-expansion-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Search expansion</a></span></li><li><span><a href=\"#Acquisition-of-word-phonetics-from-kaggle\" data-toc-modified-id=\"Acquisition-of-word-phonetics-from-kaggle-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Acquisition of word phonetics from kaggle</a></span></li><li><span><a href=\"#Random-Poking-around\" data-toc-modified-id=\"Random-Poking-around-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Random Poking around</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A little peek at Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:41:45.725188Z",
     "start_time": "2021-08-07T14:41:45.634278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147306"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexis import Lemmas\n",
    "\n",
    "lm = Lemmas()\n",
    "len(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lm` is a `Mapping` (think \"acts like a (read-only) dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:42:55.800375Z",
     "start_time": "2021-08-07T14:42:55.754223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Mapping\n",
    "\n",
    "isinstance(lm, Mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a few keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:48:26.201846Z",
     "start_time": "2021-08-07T14:48:26.133710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blond', 'kaunda', 'peacetime', 'intolerantly', \"'hood\"]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lm)[44630:44635]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the value of a `lm` item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:48:38.035161Z",
     "start_time": "2021-08-07T14:48:37.988516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blond.n.01': WordnetElement('blond.n.01'),\n",
       " 'blond.n.02': WordnetElement('blond.n.02'),\n",
       " 'blond.a.01': WordnetElement('blond.a.01')}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['blond']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it looks like it's different meanings of \"blond\". The middle letter tells us its grammatical role it's a noun (`n`) or an adjective (`a`). More on that later. \n",
    "\n",
    "And what's a `WordnetElement`?\n",
    "\n",
    "Well, it's another Mapping, apparently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:58:04.348431Z",
     "start_time": "2021-08-07T14:58:04.300704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(lm['blond']['blond.n.01'], Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:58:12.279973Z",
     "start_time": "2021-08-07T14:58:12.232986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['also_sees',\n",
       " 'instance_hypernyms',\n",
       " 'verb_groups',\n",
       " 'entailments',\n",
       " 'region_domains',\n",
       " 'substance_holonyms',\n",
       " 'part_holonyms',\n",
       " 'examples',\n",
       " 'part_meronyms',\n",
       " 'hyponyms',\n",
       " 'member_meronyms',\n",
       " 'offset',\n",
       " 'causes',\n",
       " 'definition',\n",
       " 'lemma_names',\n",
       " 'lexname',\n",
       " 'member_holonyms',\n",
       " 'in_topic_domains',\n",
       " 'lemmas',\n",
       " 'topic_domains',\n",
       " 'max_depth',\n",
       " 'hypernym_distances',\n",
       " 'name',\n",
       " 'attributes',\n",
       " 'hypernyms',\n",
       " 'min_depth',\n",
       " 'usage_domains',\n",
       " 'in_region_domains',\n",
       " 'instance_hyponyms',\n",
       " 'in_usage_domains',\n",
       " 'similar_tos',\n",
       " 'root_hypernyms',\n",
       " 'pos',\n",
       " 'frame_ids',\n",
       " 'hypernym_paths',\n",
       " 'substance_meronyms']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lm['blond']['blond.n.01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! That's a lot of information! \n",
    "\n",
    "Let's look at what the definition of `'blond.n.01'` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T15:01:13.790910Z",
     "start_time": "2021-08-07T15:01:13.744280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a person with fair skin and hair\n"
     ]
    }
   ],
   "source": [
    "print(lm['blond']['blond.n.01']['definition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... actually, let's just poke at all of them (at least those that are non-empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:59:53.942828Z",
     "start_time": "2021-08-07T14:59:53.894742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for meaning: blond.n.01\n",
      "- hyponyms: [WordnetElement('peroxide_blond.n.01'), WordnetElement('platinum_blond.n.01'), WordnetElement('towhead.n.01')]\n",
      "- offset: 9860506\n",
      "- definition: a person with fair skin and hair\n",
      "- lemma_names: ['blond', 'blonde']\n",
      "- lexname: noun.person\n",
      "- lemmas: [KvLemma('blond.n.01.blond'), KvLemma('blond.n.01.blonde')]\n",
      "- max_depth: 7\n",
      "- hypernym_distances: {(WordnetElement('physical_entity.n.01'), 6), (WordnetElement('entity.n.01'), 7), (WordnetElement('physical_entity.n.01'), 3), (WordnetElement('entity.n.01'), 4), (WordnetElement('living_thing.n.01'), 3), (WordnetElement('object.n.01'), 5), (WordnetElement('blond.n.01'), 0), (WordnetElement('organism.n.01'), 2), (WordnetElement('causal_agent.n.01'), 2), (WordnetElement('whole.n.02'), 4), (WordnetElement('person.n.01'), 1)}\n",
      "- name: blond.n.01\n",
      "- hypernyms: [WordnetElement('person.n.01')]\n",
      "- min_depth: 4\n",
      "- root_hypernyms: [Synset('entity.n.01')]\n",
      "- pos: n\n",
      "- hypernym_paths: [[WordnetElement('entity.n.01'), WordnetElement('physical_entity.n.01'), WordnetElement('causal_agent.n.01'), WordnetElement('person.n.01'), WordnetElement('blond.n.01')], [WordnetElement('entity.n.01'), WordnetElement('physical_entity.n.01'), WordnetElement('object.n.01'), WordnetElement('whole.n.02'), WordnetElement('living_thing.n.01'), WordnetElement('organism.n.01'), WordnetElement('person.n.01'), WordnetElement('blond.n.01')]]\n"
     ]
    }
   ],
   "source": [
    "meaning = 'blond.n.01'\n",
    "print(f\"Values for meaning: {meaning}\")\n",
    "for k, v in lm['blond'][meaning].items():\n",
    "    if v:\n",
    "        print(f\"- {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can get meaning information directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you made a list of these strings like `'blond.n.01'`, `'blond.a.01'`... and you wanted to access the `WordnetElement` instances with all that cool information about those specifics meanings?\n",
    "\n",
    "You could do `lm['blond']['blond.n.01']`, `lm['blond']['blond.a.01']`... But then you'd have to remember the full references `('blond', 'blond.n.01')`, `('blond', 'blond.a.01')`... \n",
    "\n",
    "You don't need to go through `lm['blond']` to get to the `WordnetElement` instance that gives you access to the meaning information -- you can use the `Synsets` store (i.e. Mapping). \n",
    "\n",
    "Note: \"synset\" is what Wordnet calls this. We'll just call is meaning for simplicity. I hope the purists won't mind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T15:18:32.695490Z",
     "start_time": "2021-08-07T15:18:32.649904Z"
    }
   },
   "outputs": [],
   "source": [
    "from lexis import Synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T15:18:35.222172Z",
     "start_time": "2021-08-07T15:18:33.364144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordnetElement('blond.n.01')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanings = Synsets()\n",
    "meanings['blond.n.01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw earlier that we had `147306` lemmas (i.e. \"words\" or more precisely \"terms\"... but really precisely, \"lemmas\"). \n",
    "\n",
    "Well, we have `117659` synsets (i.e. \"meanings\") in the `Synsets` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T15:18:41.751228Z",
     "start_time": "2021-08-07T15:18:41.704279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117659"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meanings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple lemma names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'lemma_names'` are different ways that the same meaning can be written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T15:03:13.664361Z",
     "start_time": "2021-08-07T15:03:13.616827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blond', 'blonde']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['blond']['blond.n.01']['lemma_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, `lm['blond']` and `lm['blonde']` really point to the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:47:58.932229Z",
     "start_time": "2021-08-07T14:47:58.886258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blond.n.01': WordnetElement('blond.n.01'),\n",
       " 'blond.n.02': WordnetElement('blond.n.02'),\n",
       " 'blond.a.01': WordnetElement('blond.a.01')}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['blond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:48:05.473227Z",
     "start_time": "2021-08-07T14:48:05.427081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blond.n.01': WordnetElement('blond.n.01'),\n",
       " 'blond.n.02': WordnetElement('blond.n.02'),\n",
       " 'blond.a.01': WordnetElement('blond.a.01')}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['blonde']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammatical roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the different grammatical roles that are used in the meaning identifiers (aka synset keys) of our lemmas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:55:48.454800Z",
     "start_time": "2021-08-07T14:55:45.243324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', 148478),\n",
       " ('v', 42751),\n",
       " ('s', 20895),\n",
       " ('a', 9846),\n",
       " ('r', 5619),\n",
       " ('_', 29),\n",
       " ('e', 28),\n",
       " ('u', 17),\n",
       " ('g', 17),\n",
       " ('i', 15),\n",
       " ('t', 14),\n",
       " ('p', 8),\n",
       " ('b', 7),\n",
       " ('o', 7),\n",
       " ('l', 6),\n",
       " ('d', 4),\n",
       " ('c', 2),\n",
       " ('m', 1),\n",
       " ('k', 1)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "from lexis import Lemmas\n",
    "\n",
    "lm = Lemmas()\n",
    "\n",
    "p_middle_of_dot_path = re.compile('(?P<first>[^\\.]+)\\.(?P<middle>\\w+)\\.(?P<last>[^\\.]+)')\n",
    "\n",
    "def extract_grammatical_role_from_meaning(meaning):\n",
    "    m = p_middle_of_dot_path.match(meaning)\n",
    "    if m:\n",
    "        return m.groupdict().get('middle', None) \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "c = Counter()\n",
    "for meanings in lm.values():\n",
    "    for meaning in meanings:\n",
    "        c.update(extract_grammatical_role_from_meaning(meaning))\n",
    "        \n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find words containing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T15:33:30.437074Z",
     "start_time": "2021-08-07T15:33:30.393101Z"
    }
   },
   "outputs": [],
   "source": [
    "from dol import filt_iter, cached_keys, add_ipython_key_completions, kvhead\n",
    "from lexis import Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T17:16:19.385138Z",
     "start_time": "2020-09-25T17:16:19.349030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147306"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = Lemmas()\n",
    "\n",
    "def print_definitions(words):\n",
    "    for word in words:\n",
    "        print(f\"- {word}\")\n",
    "        for k, v in lm[word].items():\n",
    "            print(f\"    {'.'.join(k.split('.')[1:])}: {v['definition']}\")\n",
    "        \n",
    "len(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T12:38:13.389563Z",
     "start_time": "2021-08-07T12:38:13.309044Z"
    }
   },
   "outputs": [],
   "source": [
    "from lexis import print_word_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T17:16:28.560951Z",
     "start_time": "2020-09-25T17:16:28.498414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substr = 'iep'\n",
    "words = list(filter(lambda w: substr in w, lm))\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T17:16:58.361875Z",
     "start_time": "2020-09-25T17:16:58.332398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- hemiepiphyte\n",
      "    n.01: a plant that is an epiphyte for part of its life\n",
      "- antiepileptic\n",
      "    n.01: a drug used to treat or prevent convulsions (as in epilepsy)\n",
      "- pieplant\n",
      "    n.01: long pinkish sour leafstalks usually eaten cooked and sweetened\n",
      "- liepaja\n",
      "    n.01: a city of southwestern Latvia on the Baltic Sea\n",
      "- semiepiphyte\n",
      "    n.01: a plant that is an epiphyte for part of its life\n",
      "- archiepiscopal\n",
      "    a.01: of or associated with an archbishop\n",
      "- tiepin\n",
      "    n.01: a pin used to hold the tie in place\n",
      "- giovanni_battista_tiepolo\n",
      "    n.01: Italian painter (1696-1770)\n",
      "- tiepolo\n",
      "    n.01: Italian painter (1696-1770)\n",
      "- antiepileptic_drug\n",
      "    n.01: a drug used to treat or prevent convulsions (as in epilepsy)\n",
      "- dnieper\n",
      "    n.01: a river that rises in Russia near Smolensk and flowing south through Belarus and Ukraine to empty into the Black Sea\n",
      "- dnieper_river\n",
      "    n.01: a river that rises in Russia near Smolensk and flowing south through Belarus and Ukraine to empty into the Black Sea\n"
     ]
    }
   ],
   "source": [
    "print_definitions(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern (regular expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:18:08.153721Z",
     "start_time": "2020-09-14T18:18:04.871629Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from lexis import Lemmas\n",
    "\n",
    "lm = Lemmas()\n",
    "\n",
    "def print_definitions(words):\n",
    "    for word in words:\n",
    "        print(f\"- {word}\")\n",
    "        for k, v in lm[word].items():\n",
    "            print(f\"    {'.'.join(k.split('.')[1:])}: {v['deffffinition']}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T13:57:39.272760Z",
     "start_time": "2021-08-07T13:57:39.109695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ono, waw, tot, kkk, ldl, anna, tenet, mom, igigi, sus, hallah, sls, pcp, mam, ofo, ene, alula, oto, civic, cfc, 101, tet, kazak, sss, ctc, aba, tevet, ara, wnw, mum, siris, tebet, tut-tut, ccc, naan, xix, tnt, peep, tut, kook, xanax, ala, eve, level, xxx, dud, aaa, dad, tdt, odo, pip, tibit, iii, sas, wow, radar, madam, yay, dmd, poop, ana, sos, bib, pop, isi, eye, gag, gig, cdc, dod, nun, pep, mym, bob, malayalam, sis, www, utu, non, ewe, aga, akka, noon, ese, rotor, ded, ppp, kayak, pap, wsw, pup, minim, nan, tat, ada, boob, mem, deed, nauruan, ma'am, succus, seles, cbc, tit, dvd, refer, toot\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from lexis import Lemmas\n",
    "\n",
    "lm = Lemmas()\n",
    "\n",
    "is_palindrome_with_at_least_3_letters = lambda w: len(w) >= 3 and w == w[::-1]\n",
    "print(*filter(is_palindrome_with_at_least_3_letters, lm), sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T12:46:01.752435Z",
     "start_time": "2021-08-07T12:46:01.706974Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wait a minute... Where's racecar?!?\n",
    "assert 'racecar' not in lm\n",
    "assert 'race_car' in lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which of these are (or rather \"can be\") a verb?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T12:46:22.314182Z",
     "start_time": "2021-08-07T12:46:22.268121Z"
    }
   },
   "source": [
    "What are the keys of the lemmas? \n",
    "\n",
    "Answer: Synset keys -- that is, an id that references a unit of meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T12:45:50.102696Z",
     "start_time": "2021-08-07T12:45:50.053908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eat.v.01',\n",
       " 'eat.v.02',\n",
       " 'feed.v.06',\n",
       " 'eat.v.04',\n",
       " 'consume.v.05',\n",
       " 'corrode.v.01']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what do are the values of the lemmas?\n",
    "list(lm['eat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That little `v` seems to be indicating that the meaning is... verbal?\n",
    "\n",
    "Let's make a function to grab that middle part of the dot path and use it to make a `is_a_verb` (more like \"can be a verb\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:28:21.257742Z",
     "start_time": "2021-08-07T14:28:21.209757Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "from lexis import Lemmas\n",
    "\n",
    "lm = Lemmas()\n",
    "\n",
    "p_middle_of_dot_path = re.compile('(?P<first>[^\\.]+)\\.(?P<middle>\\w+)\\.(?P<last>[^\\.]+)')\n",
    "\n",
    "def _extract_middle(string):\n",
    "    m = p_middle_of_dot_path.match(string)\n",
    "    if m:\n",
    "        return m.groupdict().get('middle', None) \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def grammatical_roles(lemma):\n",
    "    return Counter(map(_extract_middle, lm[lemma]))\n",
    "    \n",
    "\n",
    "assert grammatical_roles('go') == Counter({'n': 4, 'v': 30, 'a': 1})  # the lemma \"go\" can be a verb, noun, or adjective\n",
    "\n",
    "def is_a_verb(lemma):\n",
    "    return 'v' in grammatical_roles(lemma)\n",
    "    \n",
    "assert is_a_verb('go')\n",
    "assert not is_a_verb('chess')  # unlike go, chess cannot be used as a verb, apparently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "palindromes that are verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:28:50.891431Z",
     "start_time": "2021-08-07T14:28:48.117408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tot',\n",
       " 'tut-tut',\n",
       " 'peep',\n",
       " 'tut',\n",
       " 'level',\n",
       " 'pip',\n",
       " 'wow',\n",
       " 'bib',\n",
       " 'pop',\n",
       " 'eye',\n",
       " 'gag',\n",
       " 'bob',\n",
       " 'kayak',\n",
       " 'pup',\n",
       " 'tat',\n",
       " 'boob',\n",
       " 'refer',\n",
       " 'toot']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: is_a_verb(x) and is_palindrome_with_at_least_3_letters(x), lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making functions operable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making functions have arithmetic to make building a filter function more easy (and more readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:35:09.277431Z",
     "start_time": "2021-08-07T14:35:05.722116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tot',\n",
       " 'tut-tut',\n",
       " 'peep',\n",
       " 'tut',\n",
       " 'level',\n",
       " 'pip',\n",
       " 'wow',\n",
       " 'bib',\n",
       " 'pop',\n",
       " 'eye',\n",
       " 'gag',\n",
       " 'bob',\n",
       " 'kayak',\n",
       " 'pup',\n",
       " 'tat',\n",
       " 'boob',\n",
       " 'refer',\n",
       " 'toot']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from functools import wraps\n",
    "from typing import Callable\n",
    "import operator as o\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FuncsOp:\n",
    "    op: Callable\n",
    "    func1: Callable\n",
    "    func2: Callable\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.op(self.func1(*args, **kwargs), self.func2(*args, **kwargs))\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OperableFunc:\n",
    "    func: Callable = None\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        wraps(self.func)(self)\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "        \n",
    "    def __and__(self, other):\n",
    "        if isinstance(other, OperableFunc):\n",
    "            other = other.func\n",
    "        if self.func is None:  # then this is a neuteral element, yielding all ops to operand\n",
    "            return OperableFunc(other)\n",
    "        return OperableFunc(FuncsOp(o.__and__, self.func, other))\n",
    "    \n",
    "    def __or__(self, other):\n",
    "        if isinstance(other, OperableFunc):\n",
    "            other = other.func\n",
    "        if self.func is None:\n",
    "            return OperableFunc(other)\n",
    "        return OperableFunc(FuncsOp(o.__or__, self.func, other))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, OperableFunc):\n",
    "            other = other.func\n",
    "        if self.func is None:\n",
    "            return OperableFunc(other)\n",
    "        return OperableFunc(FuncsOp(o.__eq__, self.func, other))\n",
    "    \n",
    "# ATTEMPT TO AUTOMATE THIS (but doesn't work -- has to do with \"context locals\" \n",
    "# (See https://werkzeug.palletsprojects.com/en/1.0.x/local/))\n",
    "#     @staticmethod\n",
    "#     def _mk_op_func_method(op):\n",
    "#         def _op_func(self, other):\n",
    "#             if isinstance(other, OperableFunc):\n",
    "#                 other = other.func\n",
    "#             if self.func is None:\n",
    "#                 return OperableFunc(other)\n",
    "#             return OperableFunc(FuncsOp(op, self.func, other))\n",
    "\n",
    "#     for _name in ['__or__', '__eq__']:\n",
    "#         locals()[_name] = _mk_op_func_method(getattr(o, _name))\n",
    "        \n",
    "#     del _name\n",
    "    \n",
    "more_than_3_letters = OperableFunc(lambda x: len(x) >= 3)\n",
    "is_palindrome = OperableFunc(lambda w: w == w[::-1])\n",
    "\n",
    "filt = (more_than_3_letters & is_palindrome)\n",
    "assert filt('bob')\n",
    "assert not filt('bobo')\n",
    "assert not filt('mm')\n",
    "\n",
    "# note how `is_a_verb` is not an OperableFunc, but since the left hand side is, it still works!\n",
    "list(filter(more_than_3_letters & is_palindrome & is_a_verb, lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`OperableFunc()` is a \"neutral element\", but it will make it so that the left hand side is always an `OperableFunc` that can therefore cast the right hand side to an `OperableFunc`. \n",
    "\n",
    "Understood? No? Well just look at the example below where `f`, `g`, and `is_a_verb` are normal functions, and yet, since we put an `OperableFunc()` in the beginning, it works! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T14:35:56.139025Z",
     "start_time": "2021-08-07T14:35:52.776963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tot',\n",
       " 'tut-tut',\n",
       " 'peep',\n",
       " 'tut',\n",
       " 'level',\n",
       " 'pip',\n",
       " 'wow',\n",
       " 'bib',\n",
       " 'pop',\n",
       " 'eye',\n",
       " 'gag',\n",
       " 'bob',\n",
       " 'kayak',\n",
       " 'pup',\n",
       " 'tat',\n",
       " 'boob',\n",
       " 'refer',\n",
       " 'toot']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: len(x) >= 3\n",
    "g = lambda w: w == w[::-1]\n",
    "list(filter(OperableFunc() & f & g  & is_a_verb, lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only p, q, b, d, and vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T12:40:00.684677Z",
     "start_time": "2021-08-07T12:40:00.526292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from lexis import Lemmas\n",
    "\n",
    "lm = Lemmas()\n",
    "\n",
    "consonants = 'pqbd'\n",
    "vowels = 'aeiou'  # 'aeiouy'\n",
    "filt = re.compile(f'[{vowels}{consonants}]+$').match  # the pattern\n",
    "\n",
    "words = list(filter(lambda w: 2 <= len(w)  <= 7, # number of letters constraing\n",
    "                    filter(filt, lm)))  # filter for iep pattern\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:24:48.354441Z",
     "start_time": "2020-09-14T18:24:48.312320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bod\taaa\tadd\tpoa\tpop\tbeaded\taqua\tpib\tedda\tdoob\tboa\tdoi\tpadded\tiodide\tbop\tedo\tbide\teb\tbai\tquid\tde\tade\tdaba\tpid\tbaba\tpaba\tbi\tabb\tbebop\tpa\tpoop\tpb\tdea\todo\tpope\tdad\tpup\tbode\tquad\tbb\tbe\tea\tepee\tbid\tpu\tpique\tiii\tpod\tbee\tpub\tddi\tid\tbaobab\tequid\tpadua\tpipidae\topaque\tpappa\tuppp\tuub\tqepiq\tbibbed\tadp\tada\tpied\taoudad\tqed\tpupa\tbedaub\tbd\tdba\tbopeep\toboe\tado\teq\tbpi\taid\tbud\tdodo\tabo\tqaeda\taa\tpad\tpapua\tbaa\tabode\tbad\tadad\tadapid\tpapaia\tdb\tbede\tai\tpo\tdoei\tpep\teib\tdubai\tepi\tboob\tuuq\tio\tbeep\tquip\tad\tbabu\tded\tia\tdud\tda\tqi\tpaid\tpeep\tdoodad\tbeda\teddo\tboo\tpadda\tipidae\tdeep\tdope\tied\tdoped\tdopa\tii\tiaea\tuda\tdd\tbaud\tdido\tebb\tepa\tbodied\tpap\ted\tpeba\tbed\taudio\tdeed\tidea\tapoidea\tbeau\tup\tpda\tiud\tip\tdiode\tbida\tpi\tapidae\tbead\todd\tod\tdia\tbaddie\tiaa\tape\tipo\tdod\tidp\tee\tie\tdaub\tduo\tboidae\tpoe\tabed\tadobe\tpea\tdude\tdo\taided\tobi\tido\tpipe\tpe\tdoe\taiai\tpd\tbaboo\tquipu\tpood\tpapio\tequidae\tiop\tqadi\tab\tdado\tdub\tadobo\tbap\tpei\tbaeda\tequip\tdupe\taqaba\tbob\tba\tdead\tdada\tadapa\tpee\topepe\tpob\tiou\tduad\tdoodia\tdab\taide\tpip\tdipped\tbubo\tpipa\tpoi\tapia\tode\tupupa\tiq\taba\tabbe\tedp\tedd\tpia\tdue\tpud\tob\taudad\tdp\tdeb\tpie\toed\tdie\tppp\tqueue\tpapa\tadieu\tbiped\tbabe\tida\tdubuque\tdip\tuup\teu\tipod\tbade\tau\tabide\tbib\tbedded\n"
     ]
    }
   ],
   "source": [
    "print(*words, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:25:31.063557Z",
     "start_time": "2020-09-14T18:25:31.041705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- adapa\n",
      "    n.01: a Babylonian demigod or first man (sometimes identified with Adam)\n"
     ]
    }
   ],
   "source": [
    "print_definitions(['adapa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containing i, e, p in that order, with other letters in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:49:45.845876Z",
     "start_time": "2020-09-10T15:49:45.752023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = re.compile('\\w{0,2}i\\w{0,2}e\\w{0,2}p\\w{0,2}$').match  # The *i*e*p* pattern\n",
    "\n",
    "words = list(filter(lambda w: len(w) <= 6, # no more than 6 letters\n",
    "                    filter(filt, lm)))  # filter for iep pattern\n",
    "print_definitions(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T16:52:31.538431Z",
     "start_time": "2020-09-10T16:52:31.516458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tie_up, ginep, lineup, inept, pileup, tiepin, biceps, icecap, ice_up\n"
     ]
    }
   ],
   "source": [
    "print(*words, sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:50:36.437621Z",
     "start_time": "2020-09-10T15:50:36.406648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- tie_up\n",
      "    v.01: secure with or as if with ropes\n",
      "    v.02: invest so as to make unavailable for other purposes\n",
      "    v.03: restrain from moving or operating normally\n",
      "    v.01: secure in or as if in a berth or dock\n",
      "    v.05: finish the last row\n",
      "- ginep\n",
      "    n.01: tropical American tree bearing a small edible fruit with green leathery skin and sweet juicy translucent pulp\n",
      "- lineup\n",
      "    n.01: (baseball) a list of batters in the order in which they will bat\n",
      "    n.02: a line of persons arranged by police for inspection or identification\n",
      "- inept\n",
      "    s.04: not elegant or graceful in expression\n",
      "    s.02: generally incompetent and ineffectual\n",
      "    s.03: revealing lack of perceptiveness or judgment or finesse\n",
      "- pileup\n",
      "    n.01: multiple collisions of vehicles\n",
      "- tiepin\n",
      "    n.01: a pin used to hold the tie in place\n",
      "- biceps\n",
      "    n.01: any skeletal muscle having two origins (but especially the muscle that flexes the forearm)\n",
      "- icecap\n",
      "    n.01: a mass of ice and snow that permanently covers a large area of land (e.g., the polar regions or a mountain peak)\n",
      "- ice_up\n",
      "    v.01: become covered with a layer of ice; of a surface such as a window\n"
     ]
    }
   ],
   "source": [
    "print_definitions(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words that start with `s` but if you remove `s`, it's still a word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T01:07:39.923667Z",
     "start_time": "2020-09-30T01:07:38.537937Z"
    }
   },
   "outputs": [],
   "source": [
    "from lexis import Lemmas\n",
    "lm = Lemmas()\n",
    "swords = list(filter(lambda x: x.startswith('s') and x[1:] in lm, lm))  # one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T15:04:42.775776Z",
     "start_time": "2020-09-11T15:04:42.748182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711\n",
      "softener, spock, scent, spark, sbe, stickweed, screaky, salt, salp, sec, strap, sliver, slack, swish, sebs, sarawak, scuttle, stripping, swell, stole, spine, space, scar, sass, sewer, spitting, serving, sew, stalk, smite, sniffy, stripe, slake, stone, slit, sea, shoe, sweeper, swear_off, swan\n"
     ]
    }
   ],
   "source": [
    "print(len(t))\n",
    "print(*t[:40], sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T15:12:31.736352Z",
     "start_time": "2020-09-11T15:12:31.583622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dol import filt_iter, wrap_kvs, KvReader\n",
    "from lexis import Lemmas\n",
    "lm = Lemmas()\n",
    "\n",
    "@filt_iter(filt=lambda x: x.startswith('s') and x[1:] in lm)\n",
    "class Swords(Lemmas):\n",
    "    def __getitem__(self, k):\n",
    "        v = super().__getitem__(k)\n",
    "        for kk, vv in v.items():\n",
    "            yield f\"    {'.'.join(kk.split('.')[1:])}: {vv['definition']}\"\n",
    "            \n",
    "s = Swords()\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T15:12:33.128158Z",
     "start_time": "2020-09-11T15:12:33.104841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['    n.01: a substance added to another to make it less hard']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, v = s.head()\n",
    "list(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T15:13:01.208696Z",
     "start_time": "2020-09-11T15:13:01.178453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ softener -------------\n",
      "    n.01: a substance added to another to make it less hard\n",
      "------------ spock -------------\n",
      "    n.01: United States pediatrician whose many books on child care influenced the upbringing of children around the world (1903-1998)\n",
      "------------ scent -------------\n",
      "    n.02: a distinctive odor that is pleasant\n",
      "    n.02: an odor left in passing by which a person or animal can be traced\n",
      "    n.01: any property detected by the olfactory system\n",
      "    v.01: cause to smell or be smelly\n",
      "    v.02: catch the scent of; get wind of\n",
      "    v.02: apply perfume to\n",
      "------------ spark -------------\n",
      "    n.01: a momentary flash of light\n",
      "    n.01: merriment expressed by a brightness or gleam or animation of countenance\n",
      "    n.05: electrical conduction through a gas in an applied electric field\n",
      "    n.04: a small but noticeable trace of some quality that might become stronger\n",
      "    n.05: Scottish writer of satirical novels (born in 1918)\n",
      "    n.06: a small fragment of a burning substance thrown out by burning material or by friction\n",
      "    v.04: put in motion or move to act\n",
      "    v.02: emit or produce sparks\n",
      "------------ sbe -------------\n",
      "    n.01: the compass point that is one point east of due south\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "for k, v in islice(s.items(), 5):\n",
    "    print(f\"------------ {k} -------------\")\n",
    "    print(*v, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword: Query expansion.\n",
    "\n",
    "In the case of single (or few words) search corpus, it's not the query being expanded, but the searched items. \n",
    "\n",
    "We'd like to, for example, be able to find airplane noises (which may appear as airplane, airplain, plane, airplane flying, avion...), but also more specific (propeller airplane?) or more general (vehicle?).\n",
    "\n",
    "Here, the terms are tags that were used to annotate small segments of audio in a huge audio dataset (the audio is private and not available here). \n",
    "\n",
    "There's 5,179 unique terms, annotating 5,733,090 audio segments. \n",
    "\n",
    "The (term) data is dirty: There's spelling mistakes and inconsistencies, different languages, multiple (comma separated) tags, sometimes underscores and sometimes spaces are used to separate words, and more than 36% are empty or with a general (and automatic) `_unusual` tag. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T12:26:05.872026Z",
     "start_time": "2021-08-07T12:25:57.879084Z"
    }
   },
   "outputs": [],
   "source": [
    "from odat.mdat.iatis import Dacc  # pip install odat\n",
    "\n",
    "dacc = Dacc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T12:26:10.764602Z",
     "start_time": "2021-08-07T12:26:07.729597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         1797059\n",
       "_unusual                  313948\n",
       "background                118438\n",
       "normal                    116777\n",
       "good_engine_1_and_2       106673\n",
       "                          ...   \n",
       "tram_screech, traffic          1\n",
       "voix                           1\n",
       "water_intake_start             1\n",
       "voices, bell                   1\n",
       "ghhf                           1\n",
       "Length: 5179, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dacc.tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T12:26:22.871381Z",
     "start_time": "2021-08-07T12:26:22.822860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5733090"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dacc.tag_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquisition of word phonetics from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T23:38:26.273254Z",
     "start_time": "2020-09-22T23:38:25.804472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uciml/human-activity-recognition-with-smartphones',\n",
       " 'sitsawek/phonetics-articles-on-plos']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haggle import KaggleDatasets  # pip install haggle\n",
    "\n",
    "rootdir = '/D/Dropbox/_odata/kaggle/zips'\n",
    "\n",
    "s = KaggleDatasets(rootdir)\n",
    "\n",
    "if 'rtatman/english-word-frequency' in s:\n",
    "    del s['rtatman/english-word-frequency']  # just to prepare for the demo\n",
    "\n",
    "list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T23:38:58.020469Z",
     "start_time": "2020-09-22T23:38:55.457443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(results)=180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rtatman/english-word-frequency',\n",
       " 'yekenot/fasttext-crawl-300d-2m',\n",
       " 'rtatman/japanese-lemma-frequency',\n",
       " 'rtatman/glove-global-vectors-for-word-representation',\n",
       " 'averkij/lingtrain-hungarian-word-frequency',\n",
       " 'lukevanhaezebrouck/subtlex-word-frequency',\n",
       " 'facebook/fatsttext-common-crawl',\n",
       " 'facebook/fasttext-wikinews',\n",
       " 'facebook/fasttext-english-word-vectors-including-subwords',\n",
       " 'kushtej/kannada-word-frequency']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = s.search('word frequency')\n",
    "print(f\"{len(results)=}\")\n",
    "list(results)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T23:40:05.224135Z",
     "start_time": "2020-09-22T23:40:03.771416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "py2store.slib.s_zipfile.ZipReader"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = s['rtatman/english-word-frequency']\n",
    "type(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T23:40:10.007326Z",
     "start_time": "2020-09-22T23:40:09.989966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unigram_freq.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T23:40:17.050613Z",
     "start_time": "2020-09-22T23:40:17.032721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uciml/human-activity-recognition-with-smartphones',\n",
       " 'rtatman/english-word-frequency',\n",
       " 'sitsawek/phonetics-articles-on-plos']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Poking around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is just scrap -- has no order or declared sense -- still it's kept around be cause the code could inspire something more structured..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T18:28:24.815297Z",
     "start_time": "2020-09-14T18:28:24.790458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ\tADJ_SAT\tADV\tMORPHOLOGICAL_SUBSTITUTIONS\tNOUN\tVERB\tabspath\tabspaths\tall_lemma_names\tall_synsets\tcitation\tcustom_lemmas\tencoding\tensure_loaded\tfileids\tget_version\tic\tjcn_similarity\tlangs\tlch_similarity\tlemma\tlemma_count\tlemma_from_key\tlemmas\tlicense\tlin_similarity\tmorphy\tof2ss\topen\tpath_similarity\treadme\tres_similarity\troot\tss2of\tsynset\tsynset_from_pos_and_offset\tsynset_from_sense_key\tsynsets\twords\twup_similarity\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "ddir = lambda o: [x for x in dir(o) if not x.startswith('_')]\n",
    "print(*ddir(wn), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T14:46:20.928363Z",
     "start_time": "2020-09-09T14:46:20.455680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dviationniste'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(wn.words('fra'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T14:46:31.711797Z",
     "start_time": "2020-09-09T14:46:31.179334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89637"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in wn.words('jpn')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:39:42.771126Z",
     "start_time": "2020-09-09T00:39:40.109833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117659"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from lexis import Synsets, KvSynset, KvLemma\n",
    "\n",
    "\n",
    "s = Synsets()\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:27:05.814141Z",
     "start_time": "2020-09-09T00:27:05.757386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able.a.01', 'unable.a.01', 'abaxial.a.01', 'adaxial.a.01', 'acroscopic.a.01']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(s)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:27:05.837643Z",
     "start_time": "2020-09-09T00:27:05.815922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KvSynset('sound.n.01')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = s['sound.n.01']\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:27:05.865015Z",
     "start_time": "2020-09-09T00:27:05.839210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "also_sees\n",
      "attributes\n",
      "causes\n",
      "definition\n",
      "entailments\n",
      "examples\n",
      "frame_ids\n",
      "hypernym_distances\n",
      "hypernym_paths\n",
      "hypernyms\n",
      "hyponyms\n",
      "in_region_domains\n",
      "in_topic_domains\n",
      "in_usage_domains\n",
      "instance_hypernyms\n",
      "instance_hyponyms\n",
      "lemma_names\n",
      "lemmas\n",
      "lexname\n",
      "max_depth\n",
      "member_holonyms\n",
      "member_meronyms\n",
      "min_depth\n",
      "name\n",
      "offset\n",
      "part_holonyms\n",
      "part_meronyms\n",
      "pos\n",
      "region_domains\n",
      "root_hypernyms\n",
      "similar_tos\n",
      "substance_holonyms\n",
      "substance_meronyms\n",
      "topic_domains\n",
      "usage_domains\n",
      "verb_groups\n"
     ]
    }
   ],
   "source": [
    "print(*sorted(ss), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve all the key's value at once like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T23:54:48.480166Z",
     "start_time": "2020-09-08T23:54:48.429706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attributes': [],\n",
       " 'usage_domains': [],\n",
       " 'region_domains': [],\n",
       " 'definition': 'the particular auditory effect produced by a given cause',\n",
       " 'entailments': [],\n",
       " 'member_holonyms': [],\n",
       " 'hypernym_paths': [[KvSynset('entity.n.01'),\n",
       "   KvSynset('abstraction.n.06'),\n",
       "   KvSynset('attribute.n.02'),\n",
       "   KvSynset('property.n.02'),\n",
       "   KvSynset('sound_property.n.01'),\n",
       "   KvSynset('sound.n.01')]],\n",
       " 'in_usage_domains': [],\n",
       " 'verb_groups': [],\n",
       " 'pos': 'n',\n",
       " 'instance_hypernyms': [],\n",
       " 'member_meronyms': [],\n",
       " 'instance_hyponyms': [],\n",
       " 'hypernym_distances': {(KvSynset('abstraction.n.06'), 4),\n",
       "  (KvSynset('attribute.n.02'), 3),\n",
       "  (KvSynset('entity.n.01'), 5),\n",
       "  (KvSynset('property.n.02'), 2),\n",
       "  (KvSynset('sound.n.01'), 0),\n",
       "  (KvSynset('sound_property.n.01'), 1)},\n",
       " 'topic_domains': [],\n",
       " 'part_holonyms': [],\n",
       " 'lexname': 'noun.attribute',\n",
       " 'root_hypernyms': [Synset('entity.n.01')],\n",
       " 'causes': [],\n",
       " 'substance_holonyms': [],\n",
       " 'examples': ['the sound of rain on the roof', 'the beautiful sound of music'],\n",
       " 'lemmas': [Lemma('sound.n.01.sound')],\n",
       " 'lemma_names': ['sound'],\n",
       " 'part_meronyms': [],\n",
       " 'in_region_domains': [],\n",
       " 'also_sees': [],\n",
       " 'min_depth': 5,\n",
       " 'hypernyms': [KvSynset('sound_property.n.01')],\n",
       " 'offset': 4981139,\n",
       " 'name': 'sound.n.01',\n",
       " 'max_depth': 5,\n",
       " 'substance_meronyms': [],\n",
       " 'hyponyms': [KvSynset('noisiness.n.01'),\n",
       "  KvSynset('ring.n.01'),\n",
       "  KvSynset('unison.n.03'),\n",
       "  KvSynset('voice.n.01')],\n",
       " 'similar_tos': [],\n",
       " 'in_topic_domains': [],\n",
       " 'frame_ids': []}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a concept with a bit more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T23:54:00.102343Z",
     "start_time": "2020-09-08T23:54:00.075176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definition      : a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "\n",
      "examples        : ['the dog barked all night']\n",
      "\n",
      "hypernym_distances: {(KvSynset('object.n.01'), 6), (KvSynset('animal.n.01'), 7), (KvSynset('dog.n.01'), 0), (KvSynset('carnivore.n.01'), 2), (KvSynset('entity.n.01'), 13), (KvSynset('living_thing.n.01'), 4), (KvSynset('organism.n.01'), 3), (KvSynset('physical_entity.n.01'), 7), (KvSynset('object.n.01'), 11), (KvSynset('whole.n.02'), 10), (KvSynset('vertebrate.n.01'), 5), (KvSynset('whole.n.02'), 5), (KvSynset('mammal.n.01'), 4), (KvSynset('domestic_animal.n.01'), 1), (KvSynset('animal.n.01'), 2), (KvSynset('living_thing.n.01'), 9), (KvSynset('chordate.n.01'), 6), (KvSynset('organism.n.01'), 8), (KvSynset('physical_entity.n.01'), 12), (KvSynset('placental.n.01'), 3), (KvSynset('entity.n.01'), 8), (KvSynset('canine.n.02'), 1)}\n",
      "\n",
      "hypernym_paths  : [[KvSynset('entity.n.01'), KvSynset('physical_entity.n.01'), KvSynset('object.n.01'), KvSynset('whole.n.02'), KvSynset('living_thing.n.01'), KvSynset('organism.n.01'), KvSynset('animal.n.01'), KvSynset('chordate.n.01'), KvSynset('vertebrate.n.01'), KvSynset('mammal.n.01'), KvSynset('placental.n.01'), KvSynset('carnivore.n.01'), KvSynset('canine.n.02'), KvSynset('dog.n.01')], [KvSynset('entity.n.01'), KvSynset('physical_entity.n.01'), KvSynset('object.n.01'), KvSynset('whole.n.02'), KvSynset('living_thing.n.01'), KvSynset('organism.n.01'), KvSynset('animal.n.01'), KvSynset('domestic_animal.n.01'), KvSynset('dog.n.01')]]\n",
      "\n",
      "hypernyms       : [KvSynset('canine.n.02'), KvSynset('domestic_animal.n.01')]\n",
      "\n",
      "hyponyms        : [KvSynset('basenji.n.01'), KvSynset('corgi.n.01'), KvSynset('cur.n.01'), KvSynset('dalmatian.n.02'), KvSynset('great_pyrenees.n.01'), KvSynset('griffon.n.02'), KvSynset('hunting_dog.n.01'), KvSynset('lapdog.n.01'), KvSynset('leonberg.n.01'), KvSynset('mexican_hairless.n.01'), KvSynset('newfoundland.n.01'), KvSynset('pooch.n.01'), KvSynset('poodle.n.01'), KvSynset('pug.n.01'), KvSynset('puppy.n.01'), KvSynset('spitz.n.01'), KvSynset('toy_dog.n.01'), KvSynset('working_dog.n.01')]\n",
      "\n",
      "lemma_names     : ['dog', 'domestic_dog', 'Canis_familiaris']\n",
      "\n",
      "lemmas          : [Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n",
      "\n",
      "lexname         : noun.animal\n",
      "\n",
      "max_depth       : 13\n",
      "\n",
      "member_holonyms : [KvSynset('canis.n.01'), KvSynset('pack.n.06')]\n",
      "\n",
      "min_depth       : 8\n",
      "\n",
      "name            : dog.n.01\n",
      "\n",
      "offset          : 2084071\n",
      "\n",
      "part_meronyms   : [KvSynset('flag.n.07')]\n",
      "\n",
      "pos             : n\n",
      "\n",
      "root_hypernyms  : [Synset('entity.n.01')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(s['dog.n.01'].items()): \n",
    "    if v:\n",
    "        print(f\"{k:<16}: {v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:27:10.603191Z",
     "start_time": "2020-09-09T00:27:10.580547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('dog.n.01.dog'),\n",
       " Lemma('dog.n.01.domestic_dog'),\n",
       " Lemma('dog.n.01.Canis_familiaris')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = s['dog.n.01']\n",
    "ss['lemmas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:03:52.599485Z",
     "start_time": "2020-09-09T01:03:49.930467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('antonyms', [Lemma('instrumental.a.01.instrumental')]),\n",
       " ('count', 1),\n",
       " ('derivationally_related_forms', [Lemma('vocalize.v.02.vocalize')]),\n",
       " ('key', 'vocal%3:01:02::'),\n",
       " ('lang', 'eng'),\n",
       " ('name', 'vocal'),\n",
       " ('pertainyms', [Lemma('voice.n.02.voice')]),\n",
       " ('synset', Synset('vocal.a.01')),\n",
       " ('syntactic_marker', None)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = KvLemma.from_name('vocal.a.01.vocal')\n",
    "print(len(dict(lm)))\n",
    "sorted(lm.dict_of_non_empty_values().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:23:03.633177Z",
     "start_time": "2020-09-09T01:23:01.043500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KvLemma('think'),\n",
       " KvLemma('believe'),\n",
       " KvLemma('consider'),\n",
       " KvLemma('conceive')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexis import Synsets, KvSynset, KvLemma\n",
    "\n",
    "lm = KvSynset.from_name('think.v.01')['lemmas']\n",
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:33:32.413108Z",
     "start_time": "2020-09-09T01:33:32.090082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('count', 274),\n",
       " ('derivationally_related_forms',\n",
       "  [KvLemma('opinion.n.01.thought'), KvLemma('idea.n.01.thought')]),\n",
       " ('frame_ids', [5, 9]),\n",
       " ('frame_strings',\n",
       "  ['Something think something Adjective/Noun', 'Somebody think somebody']),\n",
       " ('key', 'think%2:31:01::'),\n",
       " ('lang', 'eng'),\n",
       " ('name', 'think'),\n",
       " ('synset', KvSynset('think.v.01')),\n",
       " ('syntactic_marker', None)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = KvLemma.from_name('think.v.01.think')\n",
    "sorted(lm.dict_of_non_empty_values().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:25:06.145468Z",
     "start_time": "2020-09-09T01:25:06.122896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_MutableMapping__marker',\n",
       " '__abstractmethods__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_data_of_obj',\n",
       " '_explicit_keys',\n",
       " '_from_name',\n",
       " '_id_of_key',\n",
       " '_ipython_key_completions_',\n",
       " '_key_of_id',\n",
       " '_keys_cache',\n",
       " '_max_repr_size',\n",
       " '_obj_of_data',\n",
       " '_updatable_cache',\n",
       " '_wrapped_methods',\n",
       " 'clear',\n",
       " 'dict_of_non_empty_values',\n",
       " 'from_name',\n",
       " 'get',\n",
       " 'head',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'setdefault',\n",
       " 'store',\n",
       " 'update',\n",
       " 'update_keys_cache',\n",
       " 'values']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:30:09.925031Z",
     "start_time": "2020-09-09T01:30:09.745050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('opinion.n.01.thought')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = lm.derivationally_related_forms()[0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:28:33.463171Z",
     "start_time": "2020-09-09T01:28:33.440953Z"
    }
   },
   "outputs": [],
   "source": [
    "for a in dir(t):\n",
    "    a_val = getattr(t, a)\n",
    "    if isinstance(a_val, str) and a_val == 'opinion.n.01.thought':\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:28:08.404567Z",
     "start_time": "2020-09-09T01:28:08.374811Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-13b6d69d7bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'opinion.n.01.thought'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/382/lib/python3.8/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '_name'"
     ]
    }
   ],
   "source": [
    "getattr(t, a) == 'opinion.n.01.thought'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:25:38.206609Z",
     "start_time": "2020-09-09T01:25:38.183908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('think.v.01')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm._synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:27:10.603191Z",
     "start_time": "2020-09-09T00:27:10.580547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_frame_ids',\n",
       " '_frame_strings',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_key',\n",
       " '_lang',\n",
       " '_lex_id',\n",
       " '_lexname_index',\n",
       " '_name',\n",
       " '_related',\n",
       " '_synset',\n",
       " '_syntactic_marker',\n",
       " '_wordnet_corpus_reader',\n",
       " 'also_sees',\n",
       " 'antonyms',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'count',\n",
       " 'derivationally_related_forms',\n",
       " 'entailments',\n",
       " 'frame_ids',\n",
       " 'frame_strings',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'in_region_domains',\n",
       " 'in_topic_domains',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'key',\n",
       " 'lang',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'name',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'pertainyms',\n",
       " 'region_domains',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'synset',\n",
       " 'syntactic_marker',\n",
       " 'topic_domains',\n",
       " 'usage_domains',\n",
       " 'verb_groups']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus.reader.wordnet import Lemma\n",
    "\n",
    "dir(Lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:05:24.000512Z",
     "start_time": "2020-09-09T00:05:23.971581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes: ()\n",
      "usage_domains: ()\n",
      "region_domains: ()\n",
      "entailments: ()\n",
      "member_holonyms: ()\n",
      "in_usage_domains: ()\n",
      "verb_groups: ()\n",
      "instance_hypernyms: ()\n",
      "member_meronyms: ()\n",
      "topic_domains: ()\n",
      "key: ()\n",
      "part_holonyms: ()\n",
      "count: ()\n",
      "frame_ids: ()\n",
      "frame_strings: ()\n",
      "pertainyms: ()\n",
      "causes: ()\n",
      "substance_holonyms: ()\n",
      "part_meronyms: ()\n",
      "synset: ()\n",
      "in_region_domains: ()\n",
      "derivationally_related_forms: ()\n",
      "also_sees: ()\n",
      "hypernyms: ()\n",
      "name: ()\n",
      "substance_meronyms: ()\n",
      "antonyms: ()\n",
      "hyponyms: ()\n",
      "lang: ()\n",
      "similar_tos: ()\n",
      "syntactic_marker: ()\n",
      "in_topic_domains: ()\n",
      "instance_hyponyms: ()\n"
     ]
    }
   ],
   "source": [
    "from py2store.sources import Attrs\n",
    "from i2.signatures import Sig\n",
    "\n",
    "for k, a in Attrs(lemma).items():\n",
    "    if callable(a.src):\n",
    "        print(f\"{k}: {Sig(a.src)}\")\n",
    "    else:\n",
    "        print(f\"--> {k}: {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:06:19.814269Z",
     "start_time": "2020-09-09T00:06:19.792697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('dog.n.01.dog')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:06:10.578329Z",
     "start_time": "2020-09-09T00:06:10.547568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes: []\n",
      "usage_domains: []\n",
      "region_domains: []\n",
      "entailments: []\n",
      "member_holonyms: []\n",
      "in_usage_domains: []\n",
      "verb_groups: []\n",
      "instance_hypernyms: []\n",
      "member_meronyms: []\n",
      "topic_domains: []\n",
      "key: dog%1:05:00::\n",
      "part_holonyms: []\n",
      "count: 42\n",
      "frame_ids: []\n",
      "frame_strings: []\n",
      "pertainyms: []\n",
      "causes: []\n",
      "substance_holonyms: []\n",
      "part_meronyms: []\n",
      "synset: Synset('dog.n.01')\n",
      "in_region_domains: []\n",
      "derivationally_related_forms: []\n",
      "also_sees: []\n",
      "hypernyms: []\n",
      "name: dog\n",
      "substance_meronyms: []\n",
      "antonyms: []\n",
      "hyponyms: []\n",
      "lang: eng\n",
      "similar_tos: []\n",
      "syntactic_marker: None\n",
      "in_topic_domains: []\n",
      "instance_hyponyms: []\n"
     ]
    }
   ],
   "source": [
    "for k, a in Attrs(lemma).items():\n",
    "    if callable(a.src):\n",
    "        print(f\"{k}: {a.src()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T23:54:00.102343Z",
     "start_time": "2020-09-08T23:54:00.075176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definition      : a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "\n",
      "examples        : ['the dog barked all night']\n",
      "\n",
      "hypernym_distances: {(KvSynset('object.n.01'), 6), (KvSynset('animal.n.01'), 7), (KvSynset('dog.n.01'), 0), (KvSynset('carnivore.n.01'), 2), (KvSynset('entity.n.01'), 13), (KvSynset('living_thing.n.01'), 4), (KvSynset('organism.n.01'), 3), (KvSynset('physical_entity.n.01'), 7), (KvSynset('object.n.01'), 11), (KvSynset('whole.n.02'), 10), (KvSynset('vertebrate.n.01'), 5), (KvSynset('whole.n.02'), 5), (KvSynset('mammal.n.01'), 4), (KvSynset('domestic_animal.n.01'), 1), (KvSynset('animal.n.01'), 2), (KvSynset('living_thing.n.01'), 9), (KvSynset('chordate.n.01'), 6), (KvSynset('organism.n.01'), 8), (KvSynset('physical_entity.n.01'), 12), (KvSynset('placental.n.01'), 3), (KvSynset('entity.n.01'), 8), (KvSynset('canine.n.02'), 1)}\n",
      "\n",
      "hypernym_paths  : [[KvSynset('entity.n.01'), KvSynset('physical_entity.n.01'), KvSynset('object.n.01'), KvSynset('whole.n.02'), KvSynset('living_thing.n.01'), KvSynset('organism.n.01'), KvSynset('animal.n.01'), KvSynset('chordate.n.01'), KvSynset('vertebrate.n.01'), KvSynset('mammal.n.01'), KvSynset('placental.n.01'), KvSynset('carnivore.n.01'), KvSynset('canine.n.02'), KvSynset('dog.n.01')], [KvSynset('entity.n.01'), KvSynset('physical_entity.n.01'), KvSynset('object.n.01'), KvSynset('whole.n.02'), KvSynset('living_thing.n.01'), KvSynset('organism.n.01'), KvSynset('animal.n.01'), KvSynset('domestic_animal.n.01'), KvSynset('dog.n.01')]]\n",
      "\n",
      "hypernyms       : [KvSynset('canine.n.02'), KvSynset('domestic_animal.n.01')]\n",
      "\n",
      "hyponyms        : [KvSynset('basenji.n.01'), KvSynset('corgi.n.01'), KvSynset('cur.n.01'), KvSynset('dalmatian.n.02'), KvSynset('great_pyrenees.n.01'), KvSynset('griffon.n.02'), KvSynset('hunting_dog.n.01'), KvSynset('lapdog.n.01'), KvSynset('leonberg.n.01'), KvSynset('mexican_hairless.n.01'), KvSynset('newfoundland.n.01'), KvSynset('pooch.n.01'), KvSynset('poodle.n.01'), KvSynset('pug.n.01'), KvSynset('puppy.n.01'), KvSynset('spitz.n.01'), KvSynset('toy_dog.n.01'), KvSynset('working_dog.n.01')]\n",
      "\n",
      "lemma_names     : ['dog', 'domestic_dog', 'Canis_familiaris']\n",
      "\n",
      "lemmas          : [Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n",
      "\n",
      "lexname         : noun.animal\n",
      "\n",
      "max_depth       : 13\n",
      "\n",
      "member_holonyms : [KvSynset('canis.n.01'), KvSynset('pack.n.06')]\n",
      "\n",
      "min_depth       : 8\n",
      "\n",
      "name            : dog.n.01\n",
      "\n",
      "offset          : 2084071\n",
      "\n",
      "part_meronyms   : [KvSynset('flag.n.07')]\n",
      "\n",
      "pos             : n\n",
      "\n",
      "root_hypernyms  : [Synset('entity.n.01')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(s['dog.n.01'].items()): \n",
    "    if v:\n",
    "        print(f\"{k:<16}: {v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T23:54:00.102343Z",
     "start_time": "2020-09-08T23:54:00.075176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definition      : a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "\n",
      "examples        : ['the dog barked all night']\n",
      "\n",
      "hypernym_distances: {(KvSynset('object.n.01'), 6), (KvSynset('animal.n.01'), 7), (KvSynset('dog.n.01'), 0), (KvSynset('carnivore.n.01'), 2), (KvSynset('entity.n.01'), 13), (KvSynset('living_thing.n.01'), 4), (KvSynset('organism.n.01'), 3), (KvSynset('physical_entity.n.01'), 7), (KvSynset('object.n.01'), 11), (KvSynset('whole.n.02'), 10), (KvSynset('vertebrate.n.01'), 5), (KvSynset('whole.n.02'), 5), (KvSynset('mammal.n.01'), 4), (KvSynset('domestic_animal.n.01'), 1), (KvSynset('animal.n.01'), 2), (KvSynset('living_thing.n.01'), 9), (KvSynset('chordate.n.01'), 6), (KvSynset('organism.n.01'), 8), (KvSynset('physical_entity.n.01'), 12), (KvSynset('placental.n.01'), 3), (KvSynset('entity.n.01'), 8), (KvSynset('canine.n.02'), 1)}\n",
      "\n",
      "hypernym_paths  : [[KvSynset('entity.n.01'), KvSynset('physical_entity.n.01'), KvSynset('object.n.01'), KvSynset('whole.n.02'), KvSynset('living_thing.n.01'), KvSynset('organism.n.01'), KvSynset('animal.n.01'), KvSynset('chordate.n.01'), KvSynset('vertebrate.n.01'), KvSynset('mammal.n.01'), KvSynset('placental.n.01'), KvSynset('carnivore.n.01'), KvSynset('canine.n.02'), KvSynset('dog.n.01')], [KvSynset('entity.n.01'), KvSynset('physical_entity.n.01'), KvSynset('object.n.01'), KvSynset('whole.n.02'), KvSynset('living_thing.n.01'), KvSynset('organism.n.01'), KvSynset('animal.n.01'), KvSynset('domestic_animal.n.01'), KvSynset('dog.n.01')]]\n",
      "\n",
      "hypernyms       : [KvSynset('canine.n.02'), KvSynset('domestic_animal.n.01')]\n",
      "\n",
      "hyponyms        : [KvSynset('basenji.n.01'), KvSynset('corgi.n.01'), KvSynset('cur.n.01'), KvSynset('dalmatian.n.02'), KvSynset('great_pyrenees.n.01'), KvSynset('griffon.n.02'), KvSynset('hunting_dog.n.01'), KvSynset('lapdog.n.01'), KvSynset('leonberg.n.01'), KvSynset('mexican_hairless.n.01'), KvSynset('newfoundland.n.01'), KvSynset('pooch.n.01'), KvSynset('poodle.n.01'), KvSynset('pug.n.01'), KvSynset('puppy.n.01'), KvSynset('spitz.n.01'), KvSynset('toy_dog.n.01'), KvSynset('working_dog.n.01')]\n",
      "\n",
      "lemma_names     : ['dog', 'domestic_dog', 'Canis_familiaris']\n",
      "\n",
      "lemmas          : [Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n",
      "\n",
      "lexname         : noun.animal\n",
      "\n",
      "max_depth       : 13\n",
      "\n",
      "member_holonyms : [KvSynset('canis.n.01'), KvSynset('pack.n.06')]\n",
      "\n",
      "min_depth       : 8\n",
      "\n",
      "name            : dog.n.01\n",
      "\n",
      "offset          : 2084071\n",
      "\n",
      "part_meronyms   : [KvSynset('flag.n.07')]\n",
      "\n",
      "pos             : n\n",
      "\n",
      "root_hypernyms  : [Synset('entity.n.01')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(s['dog.n.01'].items()): \n",
    "    if v:\n",
    "        print(f\"{k:<16}: {v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:27:10.603191Z",
     "start_time": "2020-09-09T00:27:10.580547Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Synset' object has no attribute 'meronyms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-4da0b2d7d0cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeronyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/382/lib/python3.8/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mtree\u001b[0;34m(self, rel, depth, cut_mark)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m             \u001b[0mtree\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_mark\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcut_mark\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mtree\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcut_mark\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-4da0b2d7d0cf>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(v)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeronyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Synset' object has no attribute 'meronyms'"
     ]
    }
   ],
   "source": [
    "v.tree(lambda v: v.meronyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T23:54:00.102343Z",
     "start_time": "2020-09-08T23:54:00.075176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definition      : a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "\n",
      "examples        : ['the dog barked all night']\n",
      "\n",
      "hypernym_distances: {(KvSynset('object.n.01'), 6), (KvSynset('animal.n.01'), 7), (KvSynset('dog.n.01'), 0), (KvSynset('carnivore.n.01'), 2), (KvSynset('entity.n.01'), 13), (KvSynset('living_thing.n.01'), 4), (KvSynset('organism.n.01'), 3), (KvSynset('physical_entity.n.01'), 7), (KvSynset('object.n.01'), 11), (KvSynset('whole.n.02'), 10), (KvSynset('vertebrate.n.01'), 5), (KvSynset('whole.n.02'), 5), (KvSynset('mammal.n.01'), 4), (KvSynset('domestic_animal.n.01'), 1), (KvSynset('animal.n.01'), 2), (KvSynset('living_thing.n.01'), 9), (KvSynset('chordate.n.01'), 6), (KvSynset('organism.n.01'), 8), (KvSynset('physical_entity.n.01'), 12), (KvSynset('placental.n.01'), 3), (KvSynset('entity.n.01'), 8), (KvSynset('canine.n.02'), 1)}\n",
      "\n",
      "hypernym_paths  : [[KvSynset('entity.n.01'), KvSynset('physical_entity.n.01'), KvSynset('object.n.01'), KvSynset('whole.n.02'), KvSynset('living_thing.n.01'), KvSynset('organism.n.01'), KvSynset('animal.n.01'), KvSynset('chordate.n.01'), KvSynset('vertebrate.n.01'), KvSynset('mammal.n.01'), KvSynset('placental.n.01'), KvSynset('carnivore.n.01'), KvSynset('canine.n.02'), KvSynset('dog.n.01')], [KvSynset('entity.n.01'), KvSynset('physical_entity.n.01'), KvSynset('object.n.01'), KvSynset('whole.n.02'), KvSynset('living_thing.n.01'), KvSynset('organism.n.01'), KvSynset('animal.n.01'), KvSynset('domestic_animal.n.01'), KvSynset('dog.n.01')]]\n",
      "\n",
      "hypernyms       : [KvSynset('canine.n.02'), KvSynset('domestic_animal.n.01')]\n",
      "\n",
      "hyponyms        : [KvSynset('basenji.n.01'), KvSynset('corgi.n.01'), KvSynset('cur.n.01'), KvSynset('dalmatian.n.02'), KvSynset('great_pyrenees.n.01'), KvSynset('griffon.n.02'), KvSynset('hunting_dog.n.01'), KvSynset('lapdog.n.01'), KvSynset('leonberg.n.01'), KvSynset('mexican_hairless.n.01'), KvSynset('newfoundland.n.01'), KvSynset('pooch.n.01'), KvSynset('poodle.n.01'), KvSynset('pug.n.01'), KvSynset('puppy.n.01'), KvSynset('spitz.n.01'), KvSynset('toy_dog.n.01'), KvSynset('working_dog.n.01')]\n",
      "\n",
      "lemma_names     : ['dog', 'domestic_dog', 'Canis_familiaris']\n",
      "\n",
      "lemmas          : [Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n",
      "\n",
      "lexname         : noun.animal\n",
      "\n",
      "max_depth       : 13\n",
      "\n",
      "member_holonyms : [KvSynset('canis.n.01'), KvSynset('pack.n.06')]\n",
      "\n",
      "min_depth       : 8\n",
      "\n",
      "name            : dog.n.01\n",
      "\n",
      "offset          : 2084071\n",
      "\n",
      "part_meronyms   : [KvSynset('flag.n.07')]\n",
      "\n",
      "pos             : n\n",
      "\n",
      "root_hypernyms  : [Synset('entity.n.01')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(s['dog.n.01'].items()): \n",
    "    if v:\n",
    "        print(f\"{k:<16}: {v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:39:27.652702Z",
     "start_time": "2020-09-08T22:39:26.765452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attributes': [],\n",
       " 'usage_domains': [],\n",
       " 'region_domains': [],\n",
       " 'definition': 'the particular auditory effect produced by a given cause',\n",
       " 'entailments': [],\n",
       " 'member_holonyms': [],\n",
       " 'hypernym_paths': [[KvSynset('entity.n.01'),\n",
       "   KvSynset('abstraction.n.06'),\n",
       "   KvSynset('attribute.n.02'),\n",
       "   KvSynset('property.n.02'),\n",
       "   KvSynset('sound_property.n.01'),\n",
       "   KvSynset('sound.n.01')]],\n",
       " 'in_usage_domains': [],\n",
       " 'verb_groups': [],\n",
       " 'pos': 'n',\n",
       " 'instance_hypernyms': [],\n",
       " 'member_meronyms': [],\n",
       " 'instance_hyponyms': [],\n",
       " 'hypernym_distances': {(KvSynset('abstraction.n.06'), 4),\n",
       "  (KvSynset('attribute.n.02'), 3),\n",
       "  (KvSynset('entity.n.01'), 5),\n",
       "  (KvSynset('property.n.02'), 2),\n",
       "  (KvSynset('sound.n.01'), 0),\n",
       "  (KvSynset('sound_property.n.01'), 1)},\n",
       " 'topic_domains': [],\n",
       " 'part_holonyms': [],\n",
       " 'lexname': 'noun.attribute',\n",
       " 'root_hypernyms': [Synset('entity.n.01')],\n",
       " 'causes': [],\n",
       " 'substance_holonyms': [],\n",
       " 'examples': ['the sound of rain on the roof', 'the beautiful sound of music'],\n",
       " 'lemmas': [Lemma('sound.n.01.sound')],\n",
       " 'lemma_names': ['sound'],\n",
       " 'part_meronyms': [],\n",
       " 'in_region_domains': [],\n",
       " 'also_sees': [],\n",
       " 'min_depth': 5,\n",
       " 'hypernyms': [KvSynset('sound_property.n.01')],\n",
       " 'offset': 4981139,\n",
       " 'name': 'sound.n.01',\n",
       " 'max_depth': 5,\n",
       " 'substance_meronyms': [],\n",
       " 'hyponyms': [KvSynset('noisiness.n.01'),\n",
       "  KvSynset('ring.n.01'),\n",
       "  KvSynset('unison.n.03'),\n",
       "  KvSynset('voice.n.01')],\n",
       " 'similar_tos': [],\n",
       " 'in_topic_domains': [],\n",
       " 'frame_ids': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(s['sound.n.01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T23:16:34.114842Z",
     "start_time": "2020-09-08T23:16:34.088674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__and__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__rand__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__ror__',\n",
       " '__rsub__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__xor__',\n",
       " 'isdisjoint']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:57:50.953810Z",
     "start_time": "2020-09-08T22:57:48.886406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the particular auditory effect produced by a given cause'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss['definition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:30:19.258803Z",
     "start_time": "2020-09-08T22:30:19.235484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({list: 28, str: 4, int: 3, set: 1})"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(type(getattr(v, x)()) for x in names_of_callable_attributes_that_have_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:19:40.214405Z",
     "start_time": "2020-09-08T22:19:40.191937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KvSynset('sound.n.01')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_type(x):\n",
    "    if isinstance(x, list):\n",
    "        if len(x) == 0:\n",
    "            return 'empty_list'\n",
    "        else:\n",
    "            x0 = x[0]\n",
    "            if isinstance(x0, list):\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:19:50.576895Z",
     "start_time": "2020-09-08T22:19:50.542706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {list: [('in_topic_domains', []),\n",
       "              ('member_holonyms', [Synset('canis.n.01'), Synset('pack.n.06')]),\n",
       "              ('lemma_names', ['dog', 'domestic_dog', 'Canis_familiaris']),\n",
       "              ('causes', []),\n",
       "              ('also_sees', []),\n",
       "              ('lemmas',\n",
       "               [Lemma('dog.n.01.dog'),\n",
       "                Lemma('dog.n.01.domestic_dog'),\n",
       "                Lemma('dog.n.01.Canis_familiaris')]),\n",
       "              ('instance_hyponyms', []),\n",
       "              ('frame_ids', []),\n",
       "              ('verb_groups', []),\n",
       "              ('similar_tos', []),\n",
       "              ('substance_holonyms', []),\n",
       "              ('root_hypernyms', [Synset('entity.n.01')]),\n",
       "              ('hyponyms',\n",
       "               [Synset('basenji.n.01'),\n",
       "                Synset('corgi.n.01'),\n",
       "                Synset('cur.n.01'),\n",
       "                Synset('dalmatian.n.02'),\n",
       "                Synset('great_pyrenees.n.01'),\n",
       "                Synset('griffon.n.02'),\n",
       "                Synset('hunting_dog.n.01'),\n",
       "                Synset('lapdog.n.01'),\n",
       "                Synset('leonberg.n.01'),\n",
       "                Synset('mexican_hairless.n.01'),\n",
       "                Synset('newfoundland.n.01'),\n",
       "                Synset('pooch.n.01'),\n",
       "                Synset('poodle.n.01'),\n",
       "                Synset('pug.n.01'),\n",
       "                Synset('puppy.n.01'),\n",
       "                Synset('spitz.n.01'),\n",
       "                Synset('toy_dog.n.01'),\n",
       "                Synset('working_dog.n.01')]),\n",
       "              ('part_holonyms', []),\n",
       "              ('topic_domains', []),\n",
       "              ('examples', ['the dog barked all night']),\n",
       "              ('part_meronyms', [Synset('flag.n.07')]),\n",
       "              ('in_usage_domains', []),\n",
       "              ('instance_hypernyms', []),\n",
       "              ('region_domains', []),\n",
       "              ('member_meronyms', []),\n",
       "              ('in_region_domains', []),\n",
       "              ('usage_domains', []),\n",
       "              ('hypernyms',\n",
       "               [Synset('canine.n.02'), Synset('domestic_animal.n.01')]),\n",
       "              ('entailments', []),\n",
       "              ('hypernym_paths',\n",
       "               [[Synset('entity.n.01'),\n",
       "                 Synset('physical_entity.n.01'),\n",
       "                 Synset('object.n.01'),\n",
       "                 Synset('whole.n.02'),\n",
       "                 Synset('living_thing.n.01'),\n",
       "                 Synset('organism.n.01'),\n",
       "                 Synset('animal.n.01'),\n",
       "                 Synset('chordate.n.01'),\n",
       "                 Synset('vertebrate.n.01'),\n",
       "                 Synset('mammal.n.01'),\n",
       "                 Synset('placental.n.01'),\n",
       "                 Synset('carnivore.n.01'),\n",
       "                 Synset('canine.n.02'),\n",
       "                 KvSynset('dog.n.01')],\n",
       "                [Synset('entity.n.01'),\n",
       "                 Synset('physical_entity.n.01'),\n",
       "                 Synset('object.n.01'),\n",
       "                 Synset('whole.n.02'),\n",
       "                 Synset('living_thing.n.01'),\n",
       "                 Synset('organism.n.01'),\n",
       "                 Synset('animal.n.01'),\n",
       "                 Synset('domestic_animal.n.01'),\n",
       "                 KvSynset('dog.n.01')]]),\n",
       "              ('attributes', []),\n",
       "              ('substance_meronyms', [])],\n",
       "             str: [('definition',\n",
       "               'a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds'),\n",
       "              ('pos', 'n'),\n",
       "              ('lexname', 'noun.animal'),\n",
       "              ('name', 'dog.n.01')],\n",
       "             int: [('max_depth', 13), ('offset', 2084071), ('min_depth', 8)],\n",
       "             set: [('hypernym_distances',\n",
       "               {(Synset('animal.n.01'), 2),\n",
       "                (Synset('animal.n.01'), 7),\n",
       "                (Synset('canine.n.02'), 1),\n",
       "                (Synset('carnivore.n.01'), 2),\n",
       "                (Synset('chordate.n.01'), 6),\n",
       "                (KvSynset('dog.n.01'), 0),\n",
       "                (Synset('domestic_animal.n.01'), 1),\n",
       "                (Synset('entity.n.01'), 8),\n",
       "                (Synset('entity.n.01'), 13),\n",
       "                (Synset('living_thing.n.01'), 4),\n",
       "                (Synset('living_thing.n.01'), 9),\n",
       "                (Synset('mammal.n.01'), 4),\n",
       "                (Synset('object.n.01'), 6),\n",
       "                (Synset('object.n.01'), 11),\n",
       "                (Synset('organism.n.01'), 3),\n",
       "                (Synset('organism.n.01'), 8),\n",
       "                (Synset('physical_entity.n.01'), 7),\n",
       "                (Synset('physical_entity.n.01'), 12),\n",
       "                (Synset('placental.n.01'), 3),\n",
       "                (Synset('vertebrate.n.01'), 5),\n",
       "                (Synset('whole.n.02'), 5),\n",
       "                (Synset('whole.n.02'), 10)})]})"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = s['dog.n.01']\n",
    "d = defaultdict(list)\n",
    "for x in names_of_callable_attributes_that_have_defaults:\n",
    "    a = getattr(v, x)()\n",
    "    d[type(a)].append((x, a))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:08:22.289623Z",
     "start_time": "2020-09-08T22:08:22.229895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['on_tap.s.02',\n",
       " 'on_tap.s.01',\n",
       " 'open.s.06',\n",
       " 'purchasable.s.02',\n",
       " 'ready.s.02',\n",
       " 'unavailable.a.01',\n",
       " 'inaccessible.s.02',\n",
       " 'out_of_stock.s.01',\n",
       " 'awake.a.01',\n",
       " 'astir.s.01']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(s)[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:08:22.924930Z",
     "start_time": "2020-09-08T22:08:22.901909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sound.n.01' in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:08:23.532261Z",
     "start_time": "2020-09-08T22:08:23.511248Z"
    }
   },
   "outputs": [],
   "source": [
    "v = s['sound.n.01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:08:23.925387Z",
     "start_time": "2020-09-08T22:08:23.902206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KvSynset('sound.n.01')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = s['sound.n.01']\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:08:25.172397Z",
     "start_time": "2020-09-08T22:08:25.150204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in_topic_domains',\n",
       " 'member_holonyms',\n",
       " 'definition',\n",
       " 'lemma_names',\n",
       " 'causes',\n",
       " 'also_sees',\n",
       " 'pos',\n",
       " 'lemmas',\n",
       " 'instance_hyponyms',\n",
       " 'frame_ids',\n",
       " 'verb_groups',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'root_hypernyms',\n",
       " 'hyponyms',\n",
       " 'max_depth',\n",
       " 'part_holonyms',\n",
       " 'topic_domains',\n",
       " 'offset',\n",
       " 'examples',\n",
       " 'part_meronyms',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'lexname',\n",
       " 'min_depth',\n",
       " 'hypernym_distances',\n",
       " 'region_domains',\n",
       " 'member_meronyms',\n",
       " 'in_region_domains',\n",
       " 'usage_domains',\n",
       " 'hypernyms',\n",
       " 'entailments',\n",
       " 'hypernym_paths',\n",
       " 'name',\n",
       " 'attributes',\n",
       " 'substance_meronyms']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:11:18.058626Z",
     "start_time": "2020-09-08T22:11:18.033198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_topic_domains': [],\n",
       " 'member_holonyms': [],\n",
       " 'definition': 'the particular auditory effect produced by a given cause',\n",
       " 'lemma_names': ['sound'],\n",
       " 'causes': [],\n",
       " 'also_sees': [],\n",
       " 'pos': 'n',\n",
       " 'lemmas': [Lemma('sound.n.01.sound')],\n",
       " 'instance_hyponyms': [],\n",
       " 'frame_ids': [],\n",
       " 'verb_groups': [],\n",
       " 'similar_tos': [],\n",
       " 'substance_holonyms': [],\n",
       " 'root_hypernyms': [Synset('entity.n.01')],\n",
       " 'hyponyms': [KvSynset('noisiness.n.01'),\n",
       "  KvSynset('ring.n.01'),\n",
       "  KvSynset('unison.n.03'),\n",
       "  KvSynset('voice.n.01')],\n",
       " 'max_depth': 5,\n",
       " 'part_holonyms': [],\n",
       " 'topic_domains': [],\n",
       " 'offset': 4981139,\n",
       " 'examples': ['the sound of rain on the roof', 'the beautiful sound of music'],\n",
       " 'part_meronyms': [],\n",
       " 'in_usage_domains': [],\n",
       " 'instance_hypernyms': [],\n",
       " 'lexname': 'noun.attribute',\n",
       " 'min_depth': 5,\n",
       " 'hypernym_distances': {(Synset('abstraction.n.06'), 4),\n",
       "  (Synset('attribute.n.02'), 3),\n",
       "  (Synset('entity.n.01'), 5),\n",
       "  (Synset('property.n.02'), 2),\n",
       "  (KvSynset('sound.n.01'), 0),\n",
       "  (Synset('sound_property.n.01'), 1)},\n",
       " 'region_domains': [],\n",
       " 'member_meronyms': [],\n",
       " 'in_region_domains': [],\n",
       " 'usage_domains': [],\n",
       " 'hypernyms': [KvSynset('sound_property.n.01')],\n",
       " 'entailments': [],\n",
       " 'hypernym_paths': [[Synset('entity.n.01'),\n",
       "   Synset('abstraction.n.06'),\n",
       "   Synset('attribute.n.02'),\n",
       "   Synset('property.n.02'),\n",
       "   Synset('sound_property.n.01'),\n",
       "   KvSynset('sound.n.01')]],\n",
       " 'name': 'sound.n.01',\n",
       " 'attributes': [],\n",
       " 'substance_meronyms': []}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:11:43.487275Z",
     "start_time": "2020-09-08T22:11:43.462647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('entity.n.01'),\n",
       "  Synset('abstraction.n.06'),\n",
       "  Synset('attribute.n.02'),\n",
       "  Synset('property.n.02'),\n",
       "  Synset('sound_property.n.01'),\n",
       "  KvSynset('sound.n.01')]]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v['hypernym_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:08:39.336817Z",
     "start_time": "2020-09-08T22:08:39.312285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('entity.n.01'),\n",
       "  Synset('abstraction.n.06'),\n",
       "  Synset('attribute.n.02'),\n",
       "  Synset('property.n.02'),\n",
       "  Synset('sound_property.n.01'),\n",
       "  KvSynset('sound.n.01')]]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.hypernym_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:10:14.364131Z",
     "start_time": "2020-09-08T22:10:14.330870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_topic_domains\n",
      "member_holonyms\n",
      "definition\n",
      "lemma_names\n",
      "causes\n",
      "also_sees\n",
      "pos\n",
      "lemmas\n",
      "instance_hyponyms\n",
      "frame_ids\n",
      "verb_groups\n",
      "similar_tos\n",
      "substance_holonyms\n",
      "root_hypernyms\n",
      "hyponyms\n",
      "max_depth\n",
      "part_holonyms\n",
      "topic_domains\n",
      "offset\n",
      "examples\n",
      "part_meronyms\n",
      "in_usage_domains\n",
      "instance_hypernyms\n",
      "lexname\n",
      "min_depth\n",
      "hypernym_distances\n",
      "region_domains\n",
      "member_meronyms\n",
      "in_region_domains\n",
      "usage_domains\n",
      "hypernyms\n",
      "entailments\n",
      "hypernym_paths\n",
      "name\n",
      "attributes\n",
      "substance_meronyms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'in_topic_domains': [],\n",
       " 'member_holonyms': [],\n",
       " 'definition': 'the particular auditory effect produced by a given cause',\n",
       " 'lemma_names': ['sound'],\n",
       " 'causes': [],\n",
       " 'also_sees': [],\n",
       " 'pos': 'n',\n",
       " 'lemmas': [Lemma('sound.n.01.sound')],\n",
       " 'instance_hyponyms': [],\n",
       " 'frame_ids': [],\n",
       " 'verb_groups': [],\n",
       " 'similar_tos': [],\n",
       " 'substance_holonyms': [],\n",
       " 'root_hypernyms': [Synset('entity.n.01')],\n",
       " 'hyponyms': [KvSynset('noisiness.n.01'),\n",
       "  KvSynset('ring.n.01'),\n",
       "  KvSynset('unison.n.03'),\n",
       "  KvSynset('voice.n.01')],\n",
       " 'max_depth': 5,\n",
       " 'part_holonyms': [],\n",
       " 'topic_domains': [],\n",
       " 'offset': 4981139,\n",
       " 'examples': ['the sound of rain on the roof', 'the beautiful sound of music'],\n",
       " 'part_meronyms': [],\n",
       " 'in_usage_domains': [],\n",
       " 'instance_hypernyms': [],\n",
       " 'lexname': 'noun.attribute',\n",
       " 'min_depth': 5,\n",
       " 'hypernym_distances': {(Synset('abstraction.n.06'), 4),\n",
       "  (Synset('attribute.n.02'), 3),\n",
       "  (Synset('entity.n.01'), 5),\n",
       "  (Synset('property.n.02'), 2),\n",
       "  (KvSynset('sound.n.01'), 0),\n",
       "  (Synset('sound_property.n.01'), 1)},\n",
       " 'region_domains': [],\n",
       " 'member_meronyms': [],\n",
       " 'in_region_domains': [],\n",
       " 'usage_domains': [],\n",
       " 'hypernyms': [KvSynset('sound_property.n.01')],\n",
       " 'entailments': [],\n",
       " 'hypernym_paths': [[Synset('entity.n.01'),\n",
       "   Synset('abstraction.n.06'),\n",
       "   Synset('attribute.n.02'),\n",
       "   Synset('property.n.02'),\n",
       "   Synset('sound_property.n.01'),\n",
       "   KvSynset('sound.n.01')]],\n",
       " 'name': 'sound.n.01',\n",
       " 'attributes': [],\n",
       " 'substance_meronyms': []}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T00:44:22.110717Z",
     "start_time": "2020-09-08T00:44:21.249644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['son']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.lemma_names(lang='fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T00:45:06.923521Z",
     "start_time": "2020-09-08T00:45:06.547012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.lemma_names(lang='jpn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T18:51:55.918803Z",
     "start_time": "2020-09-08T18:51:54.334848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lexis.Synsets"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexis import Synsets\n",
    "\n",
    "Synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T18:51:19.090793Z",
     "start_time": "2020-09-08T18:51:19.066020Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Attrs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-dd188c01f8ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAttrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Attrs' is not defined"
     ]
    }
   ],
   "source": [
    "[a for a in Attrs(v) if callable(getattr(v, a)) and len(Sig(getattr(v, a))) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:44:26.328562Z",
     "start_time": "2020-09-08T19:44:26.295034Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of lexis failed: Traceback (most recent call last):\n",
      "  File \"/Users/twhalen/.virtualenvs/382/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/twhalen/.virtualenvs/382/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/twhalen/.pyenv/versions/3.8.2/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/twhalen/.pyenv/versions/3.8.2/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/D/Dropbox/dev/p3/proj/i/py2store/lexis.py\", line 35, in <module>\n",
      "    from lexis import Synsets\n",
      "ImportError: cannot import name 'Synsets' from 'lexis' (/D/Dropbox/dev/p3/proj/i/py2store/lexis.py)\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.wordnet.Synset"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T18:52:46.561702Z",
     "start_time": "2020-09-08T18:52:46.530949Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-2408f3378881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpy2store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSynsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'v' is not defined"
     ]
    }
   ],
   "source": [
    "from py2store.sources import Attrs\n",
    "from lexis import Synsets\n",
    "\n",
    "w = Attrs(v)\n",
    "list(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:51:16.894385Z",
     "start_time": "2020-09-08T19:51:15.995799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lexis\n"
     ]
    }
   ],
   "source": [
    "import lexis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a for a in Attrs(v) if callable(getattr(v, a)) and len(Sig(getattr(v, a))) == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:03:13.488830Z",
     "start_time": "2020-09-08T19:03:13.460901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in_topic_domains',\n",
       " 'member_holonyms',\n",
       " 'definition',\n",
       " 'causes',\n",
       " 'also_sees',\n",
       " 'pos',\n",
       " 'instance_hyponyms',\n",
       " 'frame_ids',\n",
       " 'verb_groups',\n",
       " 'similar_tos',\n",
       " 'root_hypernyms',\n",
       " 'substance_holonyms',\n",
       " 'hyponyms',\n",
       " 'max_depth',\n",
       " 'part_holonyms',\n",
       " 'topic_domains',\n",
       " 'offset',\n",
       " 'examples',\n",
       " 'part_meronyms',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'lexname',\n",
       " 'min_depth',\n",
       " 'region_domains',\n",
       " 'member_meronyms',\n",
       " 'in_region_domains',\n",
       " 'usage_domains',\n",
       " 'hypernyms',\n",
       " 'entailments',\n",
       " 'hypernym_paths',\n",
       " 'name',\n",
       " 'attributes',\n",
       " 'substance_meronyms']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from i2.signatures import Sig\n",
    "from py2store.sources import Attrs\n",
    "from nltk.corpus.reader.wordnet import Synset\n",
    "\n",
    "[name for name, a in Attrs(Synset).items() if callable(a.src) and len(Sig(a.src)) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:03:42.087679Z",
     "start_time": "2020-09-08T19:03:42.059446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_similarity(self, other, ic, verbose=False)\n",
      "lemma_names(self, lang='eng')\n",
      "lemmas(self, lang='eng')\n",
      "lin_similarity(self, other, ic, verbose=False)\n",
      "closure(self, rel, depth=-1)\n",
      "lch_similarity(self, other, verbose=False, simulate_root=True)\n",
      "lowest_common_hypernyms(self, other, simulate_root=False, use_min_depth=False)\n",
      "common_hypernyms(self, other)\n",
      "wup_similarity(self, other, verbose=False, simulate_root=True)\n",
      "hypernym_distances(self, distance=0, simulate_root=False)\n",
      "shortest_path_distance(self, other, simulate_root=False)\n",
      "tree(self, rel, depth=-1, cut_mark=None)\n",
      "path_similarity(self, other, verbose=False, simulate_root=True)\n",
      "jcn_similarity(self, other, ic, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "for name, a in Attrs(Synset).items():\n",
    "    if callable(a.src) and len(Sig(a.src)) > 1:\n",
    "        print(f\"{name}{Sig(a.src)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:30:31.146544Z",
     "start_time": "2020-09-08T19:30:31.122860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('sound.n.01')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['sound.n.01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:32:49.563226Z",
     "start_time": "2020-09-08T19:32:49.538081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sig ()>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sig.defaults\n",
    "t = next(iter(Attrs(Synset).values()))\n",
    "Sig(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:42:53.041852Z",
     "start_time": "2020-09-08T19:42:53.008367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KvSynset('sound.n.01')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_of_non_callable_attributes = {name for name, a in Attrs(Synset).items() if not callable(a.src)}\n",
    "\n",
    "names_of_callable_attributes_that_have_defaults = {\n",
    "    name for name, a in Attrs(Synset).items() \n",
    "    if callable(a.src) and len(Sig(a.src)) - len(Sig(a.src).defaults) == 1}\n",
    "\n",
    "kv_synset_key_names = names_of_non_callable_attributes | names_of_callable_attributes_that_have_defaults\n",
    "\n",
    "from dol import Store, KvReader\n",
    "\n",
    "class KvSynset(Store, Synset):\n",
    "    key_names = kv_synset_key_names\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        attr = getattr(self, k)\n",
    "        if callable(attr):\n",
    "            return attr()\n",
    "        else:\n",
    "            return attr\n",
    "        \n",
    "    def __iter__(self):\n",
    "        yield from key_names\n",
    "        \n",
    "    def __contains__(self, k):\n",
    "        return k in self.key_names\n",
    "    \n",
    "    def __len__(self, k):\n",
    "        return len()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}('{self._name}')\"\n",
    "\n",
    "    \n",
    "KvSynset(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:33:36.018154Z",
     "start_time": "2020-09-08T19:33:35.994480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig = Sig(v.shortest_path_distance)\n",
    "len(sig) - len(sig.defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:15:16.377244Z",
     "start_time": "2020-09-08T19:15:16.351304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('None')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py2store import Store\n",
    "\n",
    "class KvSynset(Synset, Store):\n",
    "    pass\n",
    "\n",
    "Synset('sound.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:15:42.376021Z",
     "start_time": "2020-09-08T19:15:42.351521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('sound.n.01')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:05:57.853417Z",
     "start_time": "2020-09-08T19:05:57.829709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1526795099383855"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['sound.n.01'].lch_similarity(s['sound.n.02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:07:04.027903Z",
     "start_time": "2020-09-08T19:07:04.003994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(Synset('abstraction.n.06'), 4),\n",
       " (Synset('attribute.n.02'), 3),\n",
       " (Synset('entity.n.01'), 5),\n",
       " (Synset('property.n.02'), 2),\n",
       " (Synset('sound.n.01'), 0),\n",
       " (Synset('sound_property.n.01'), 1)}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['sound.n.01'].hypernym_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:10:27.837315Z",
     "start_time": "2020-09-08T19:10:27.813974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('sound_property.n.01')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:12:35.100545Z",
     "start_time": "2020-09-08T19:12:35.077183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('sound.n.01'),\n",
       " [Synset('noisiness.n.01'), [Synset('boisterousness.n.02')]],\n",
       " [Synset('ring.n.01')],\n",
       " [Synset('unison.n.03')],\n",
       " [Synset('voice.n.01'), [Synset('androglossia.n.01')]]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.tree(lambda v: v.hyponyms(), depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T19:08:40.801139Z",
     "start_time": "2020-09-08T19:08:40.777273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01'), Synset('abstraction.n.06')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['sound.n.01'].common_hypernyms(s['sound.n.02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['sound.n.01'].lch_similarity(s['sound.n.02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T18:54:18.517691Z",
     "start_time": "2020-09-08T18:54:18.492068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in_topic_domains',\n",
       " 'member_holonyms',\n",
       " 'res_similarity',\n",
       " 'definition',\n",
       " 'lemma_names',\n",
       " 'causes',\n",
       " 'also_sees',\n",
       " 'pos',\n",
       " 'lemmas',\n",
       " 'instance_hyponyms',\n",
       " 'lin_similarity',\n",
       " 'frame_ids',\n",
       " 'verb_groups',\n",
       " 'closure',\n",
       " 'similar_tos',\n",
       " 'lch_similarity',\n",
       " 'root_hypernyms',\n",
       " 'lowest_common_hypernyms',\n",
       " 'substance_holonyms',\n",
       " 'hyponyms',\n",
       " 'max_depth',\n",
       " 'common_hypernyms',\n",
       " 'part_holonyms',\n",
       " 'topic_domains',\n",
       " 'offset',\n",
       " 'examples',\n",
       " 'wup_similarity',\n",
       " 'part_meronyms',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'lexname',\n",
       " 'min_depth',\n",
       " 'hypernym_distances',\n",
       " 'region_domains',\n",
       " 'member_meronyms',\n",
       " 'in_region_domains',\n",
       " 'shortest_path_distance',\n",
       " 'tree',\n",
       " 'path_similarity',\n",
       " 'usage_domains',\n",
       " 'hypernyms',\n",
       " 'entailments',\n",
       " 'hypernym_paths',\n",
       " 'name',\n",
       " 'attributes',\n",
       " 'substance_meronyms',\n",
       " 'jcn_similarity']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Attrs(Synset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T18:54:49.889689Z",
     "start_time": "2020-09-08T18:54:49.866337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function nltk.corpus.reader.wordnet._WordNetObject.attributes(self)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Attrs(Synset)['attributes']\n",
    "t.src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T23:59:10.099461Z",
     "start_time": "2020-09-07T23:59:10.074132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['min_depth',\n",
       " 'region_domains',\n",
       " 'topic_domains',\n",
       " 'root_hypernyms',\n",
       " 'hyponyms',\n",
       " 'causes',\n",
       " 'pos',\n",
       " 'part_holonyms',\n",
       " 'max_depth',\n",
       " 'entailments',\n",
       " 'hypernym_paths',\n",
       " 'in_usage_domains',\n",
       " 'substance_holonyms',\n",
       " 'member_meronyms',\n",
       " 'instance_hyponyms',\n",
       " 'similar_tos',\n",
       " 'examples',\n",
       " 'frame_ids',\n",
       " 'in_topic_domains',\n",
       " 'also_sees',\n",
       " 'hypernyms',\n",
       " 'instance_hypernyms',\n",
       " 'member_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'name',\n",
       " 'part_meronyms',\n",
       " 'usage_domains',\n",
       " 'offset',\n",
       " 'definition',\n",
       " 'verb_groups',\n",
       " 'in_region_domains',\n",
       " 'attributes',\n",
       " 'lexname']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from i2.signatures import Sig\n",
    "from py2store.sources import Attrs\n",
    "[a for a in Attrs(v) if len(Sig(getattr(v, a))) == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T23:54:48.733508Z",
     "start_time": "2020-09-07T23:54:48.710995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v.definition()='the particular auditory effect produced by a given cause'\n",
      "v.hyponyms()=[Synset('noisiness.n.01'), Synset('ring.n.01'), Synset('unison.n.03'), Synset('voice.n.01')]\n",
      "v.hypernyms()=[Synset('sound_property.n.01')]\n",
      "v.also_sees()=[]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{v.definition()=}\")\n",
    "print(f\"{v.hyponyms()=}\")\n",
    "print(f\"{v.hypernyms()=}\")\n",
    "print(f\"{v.also_sees()=}\")\n",
    "print(f\"{v.also_sees()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "172px",
    "left": "64px",
    "top": "110px",
    "width": "885px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
